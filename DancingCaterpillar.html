<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <title>Narcissus and the Machine by Haoheng</title>
      <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
      <link rel="stylesheet" type="text/css" href="styles/main.css">
  </head>
  <script src="https://kit.fontawesome.com/80b107c462.js" crossorigin="anonymous"></script>
  <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

  <body>
      <header class="title">
        <span>
          H______T
        </span>
      </header>

      <nav class="nav navbar-light justify-content-center">
          <li class="nav-item nav-item2 navtop">
            <a class="nav-link" aria-current="page" href="index.html" style="color: rgb(110, 110, 110);">Home</a>
          </li>
          <li class="nav-item nav-item2 navtop">
            <a class="nav-link" href="aboutme.html" style="color: rgb(110, 110, 110);">About</a>
          </li>
      </nav>

      <video autoplay muted loop style="width: 100%; ">
          <source src="images/Dancing Caterpillar/dancingCaterpillar.mp4" type="video/mp4">
      </video>
    
    <main>
      <article>
        <header class="titlename">Dancing Caterpillar</header>
        <p class="subtitle">
          Collaborative Academic Project</br>
          March 2023 to May 2023</br>
          Teammate: Pawel Bejm, Arthur van Havre</br>
          Instructor: Chuck Hoberman
        </p>
        <section class="imgholder">
          <h3 class="project-name">
            1. Concept
          </h3>
          <img src="images/Narcissus Machine/human_AI_mirror.jpg" style="width: 100%;">
          <figcaption style="text-align: center;">AI As a Mirror</figcaption>
          <p>
            "Narcissus and the Machine" is an interactive art installation that creates a dialogue between humans and artificial intelligence (AI) not through the medium of language, but through the language of movement.
          </br></br>
            This project is born from a provocative inquiry: if AI has its own consciousness, how would it perceive humans? By envisioning AI as a "mirror", can we gain a deeper insight into our own selves by observing our "reflections" through the AI's perspective?
          </br></br>
            In response, we have breathed life into such an AI entity. Though in its nascent stage, this AI can observe human movements and translate them into various water motion expressions, encompassing the majesty of ocean waves, the descent of waterfalls, the gentle patter of rainfall, and the serene spread of ripples.
          </p>
        </section>

        <section style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem;" class="imgholder">
          <img src="images/Narcissus Machine/oceanwave.jpg" style="width: 100%; grid-column: 1/span 1;">
          <img src="images/Narcissus Machine/waterfall.jpg" style="width: 100%; grid-column: 2/span 1;">
          <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ocean wave</figcaption>
          <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Waterfall</figcaption>
          <img src="images/Narcissus Machine/ripple.jpg" style="width: 100%; grid-column: 1/span 1;">
          <img src="images/Narcissus Machine/maxresdefault.jpg" style="width: 100%; grid-column: 2/span 1;">
          <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ripple</figcaption>
          <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Rainfall</figcaption>
        </section>

        <section class="imgholder">
          <p>
            Water mirrors the reflection of the individual gazing upon its surface. The AI-powered machine is able to do the same work, which explains the reason why we use water as the main element of our project. The project draws inspiration from the myth of Narcissus, riffing on the title’s canonical fascination with appearance, reflection, and embodiment through water.
          </p>
          <img src="images/Narcissus Machine/Narcissus.png" style="width: 100%; grid-column: 1/span 1;">
          <figcaption>Caravaggio depicted a young page dressed in a elegant brocade doublet, leaning over the water with his hands, as he looks at his own distorted reflection.</figcaption>
        </section>

        <section class="imgholder">
          <h3 class="project-name">
            2. Model Training
          </h3>
          <section style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem;" class="imgholder">
            <img src="images/Narcissus Machine/opticalFlow_openCV.jpg" style="width: 100%; grid-column: 1/span 1;">
            <p style="width: 100%; grid-column: 2/span 1;"> 
              Optical flow is a task of per-pixel motion estimation between two  consecutive frames in one video. Basically, the Optical Flow task implies the calculation of the shift vector for pixel  as an object displacement difference between two neighboring images. The  main idea of Optical Flow is to estimate the object’s displacement vector caused by it’s motion or camera movements.[1]
            </p>
            <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;"><a href="https://learnopencv.com/optical-flow-in-opencv/">Image source</a></figcaption>
          </section>

          <section style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem;" class="imgholder">
            <img src="images/Narcissus Machine/ocean_waves_97.png" style="width: 100%; grid-column: 1/span 1;">
            <img src="images/Narcissus Machine/waterfall_223.png" style="width: 100%; grid-column: 2/span 1;">
            <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ocean wave</figcaption>
            <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Waterfall</figcaption>
            <img src="images/Narcissus Machine/waterripples_57.png" style="width: 100%; grid-column: 1/span 1;">
            <img src="images/Narcissus Machine/rainfall_154.png" style="width: 100%; grid-column: 2/span 1;">
            <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ripple</figcaption>
            <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Rainfall</figcaption>
          </section>

          <section>
            <p>
              For each category of water movements, we curated one or two videos and analyzed them using Optical Flow in OpenCV (Python). This analysis allows us to determine the length and direction of an object's movement between consecutive frames by the color of a pixel:
            </br>
              <li>Cyan represents movement to the left.</li>
              <li>Light Coral represents movement to the right.</li>
              <li>Midnight Blue represents movement upwards.</li>
              <li>Light Green represents movement downwards.</li>
            </br>  
              The provided screenshots showcase examples of ocean waves, waterfalls, rainfall, and ripples that have been processed with optical flow. We converted video frames into .jpg format to serve as the training set, with each category containing between 700 and 1000 images. A significant consideration was deciding whether to focus on learning the global or local features of the water patterns. This was especially relevant for categories like ripples and rainfalls, where the images featured large blank areas. To address this, we implemented random cropping (512x512 pixels) during the training. This technique aims to train the model to focus more on the characteristics of water movements, such as smooth curves, short vertical lines, and concentric circles, rather than the sparsity level. It not only enabled the use of high-resolution images (1852x1480 pixels) for training to prevent loss of detail but also allowed us to use low-resolution webcam videos as inputs to ensure smoothness.
            </br>
          </p>
          <img src="images/Narcissus Machine/TheArchitectureofVGG16.jpg" style="width: 100%; grid-column: 1/span 1;">
          <figcaption style="text-align: center;">
          The architecture of VGG16
          </br>
          Source: Researchgate.net
          </figcaption>
          <p>
          </br>
              We trained a VGG model on this dataset for 99 epochs, achieving an accuracy of 0.9753 and a loss of 0.0890 on the training set. When tested on a test set of 356 images, the model achieved 100% accuracy in classification.
            </p>
          </section>
        </section>


        <section class="imgholder">
          <h3 class="project-name">
            3. Real-time Classifier
          </h3>
          <img src="images/Narcissus Machine/webcam_capture.jpg" style="width: 100%; grid-column: 1/span 1;">
          <figcaption style="text-align: center;">Webcam Video Processed with Optical Flow </br>
            Classified as “ocean wave”</figcaption>
          <p>Utilizing Optical Flow in OpenCV (Python), we were able to convert each webcam frame into a color map, mirroring the approach taken during the training process. This enabled us to prompt the model to classify each frame accordingly. For instance, a frame capturing a person with their arms open and waving could be classified under the category of ocean waves, as it bears the closest resemblance to the images within that class.</p>
        </section>


        <section class="imgholder">
          <h3 class="project-name">
            4. Animation
          </h3>
          <p>We aimed to generate artistic animations of water that correspond to the outcomes of the real-time classifier. For instance, if the movements of an audience member are identified as resembling an "ocean wave," we anticipate the animation will display patterns of ocean waves. If the movements shift and are recognized as a different type of water motion, we likewise expect the animation to transition smoothly to reflect this change.</p>
          <img src="images/Narcissus Machine/wave_animation.jpg" style="width: 100%; ">
          <figcaption style="text-align: center;">Animation: ocean wave</figcaption>
          <p></br></p>
          <img src="images/Narcissus Machine/ripple_animation.jpg" style="width: 100%; ">
          <figcaption style="text-align: center;">Animation: ripple</figcaption>
          <p>
          </br>
            We designed a 50x50 grid, where each cell features a white dot. By parametrically adjusting the vertical movements of these dots, we created movement patterns that simulate various types of water motion.
          </br></br>
            The final challenge was seamlessly integrating the animation on the front-end server with the classifier on the back-end server. Overcoming the inherent time delays in data transmission was a complex task. Fortunately, WebSocket technology enabled us to significantly reduce this asynchrony. Establishing a bidirectional communication pathway between the front-end and back-end using WebSocket allowed the front-end to continuously listen to data from the back-end, and vice versa. This method proved to be more efficient than traditional HTTP approaches for real-time data exchange.
          </p>
        </section>


        <section class="imgholder">
          <h3 class="project-name">
            5. Built Environment and Feedback Loop
          </h3>
          <img src="images/Narcissus Machine/built_env2.jpg" style="width: 100%; ">
          <figcaption style="text-align: center;">Built environment: right view</figcaption>
          <p></br></p>
          <img src="images/Narcissus Machine/built_env1.jpg" style="width: 100%; ">
          <figcaption style="text-align: center;">Built environment: top view</figcaption>
          <p></br></p>
          <img src="images/Narcissus Machine/built_env3.jpg" style="width: 100%; ">
          <figcaption style="text-align: center;">Built environment: isometric view</figcaption>
          <p>
          </br>
            The installation was configured in a dark space in the school building, featuring two intersecting projections and a white tulle dominating the center of the space. A projector was suspended from the ceiling at the rear, while the other was stationed on a table to one side. This arrangement facilitated an interplay of light upon the tulle, creating a dynamic pattern of illumination that penetrated the semi-transparent fabric and illuminated the opposite walls.
          </br></br>
            This setup created a highly immersive experience for participants, allowing for an interactive engagement with the space. In addition to human body movements, the projected animation was also captured by the webcam, consequently augmenting the subsequent animation. This process enriched the animation, leading to a cyclical interaction wherein participants, often subconsciously, adapted their movements in response to the visual stimuli. Consequently, a feedback loop emerged, illustrating a dynamic interplay between human participants and the technological components of the installation.
          </br></br>
            A notable observation was the participants' engagement with their shadows. Any movement close to the projector was significantly magnified, creating an enlarged silhouette on the walls. These silhouettes, once detected by the webcam, promptly influenced the subsequent animation. This feature was particularly well-received, allowing participants to experiment with their body movements in front of the projector and observe the resultant effects on the animation.
          </p>
        </section>

      </article>
    </main>


    <footer class="nav navbar-light justify-content-center" style="padding-top: 6rem;">
      <li class="nav-item nav-item2 navbottom">
        <a class="nav-link" aria-current="page" href="index.html" style="color: rgb(110, 110, 110);">Home</a>
      </li>
      <li class="nav-item nav-item2 navbottom">
        <a class="nav-link" href="aboutme.html" style="color: rgb(110, 110, 110);">About</a>
      </li>
    </footer>

        <button onclick="topFunction()" id="myBtn" title="Go to top">↑</button>
    <a href="https://www.linkedin.com/in/haoheng-tang-38b4131a3/" target="_blank"><i class="fa-brands fa-linkedin" id="myLink" style="bottom: 20%;"></i></a>
    <a href="https://github.com/Haoheng-Tang" target="_blank"><i class="fa-brands fa-github" id="myLink" style="bottom: 15%;"></i></a> 
    <a href="https://www.instagram.com/tanghownn/" target="_blank"><i class="fa-brands fa-instagram" id="myLink" style="bottom: 10%;"></i></a>
    <a href="https://www.youtube.com/channel/UC-qlML6fI94fiUZdij8MXTQ" target="_blank"><i class="fa-brands fa-youtube" id="myLink" style="bottom: 5%;"></i></a> 
          
    <script src="scripts/main.js"></script>
  </body>
</html>