<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <title>Narcissus and the Machine by Haoheng</title>
      <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
      <link rel="stylesheet" type="text/css" href="styles/main.css">
  </head>
  <script src="https://kit.fontawesome.com/80b107c462.js" crossorigin="anonymous"></script>
  
  <body>
      <header class="title">
          H______T
      </header>

      <nav class="nav navbar-light justify-content-center">
          <li class="nav-item nav-item2">
            <a class="nav-link" aria-current="page" href="index.html" style="color: rgb(110, 110, 110);">Home</a>
          </li>
          <li class="nav-item nav-item2">
            <a class="nav-link" href="aboutme.html" style="color: rgb(110, 110, 110);">About</a>
          </li>
      </nav>

      <video autoplay muted controls style="width: 100%; ">
          <source src="images/Narcissus Machine/Narcissus_Machine_compressed.mp4" type="video/mp4">
      </video>
    
    <main>
      <article style="width: 85%; margin-left: auto; margin-right: auto;">
        <header class="titlename">Narcissus and the Machine</header>
        <p class="subtitle">
          Collaborative Academic Project</br>
          Oct 2023 to Dec 2023</br>
          Teammate: Carly Lave, Sky Araki-Russel</br>
          Instructor: Panagiotis Michalatos 
        </p>
        <section class="imgholder">
          <h3 class="project-name">
            1. Concept
          </h3>
          <img src="images/Narcissus Machine/human_AI_mirror.jpg" style="width: 100%;">
          <figcaption style="text-align: center;">AI As a Mirror</figcaption>
          <p>
            "Narcissus and the Machine" is an interactive art installation that creates a dialogue between humans and artificial intelligence (AI) not through the medium of language, but through the language of movement.
          </br></br>
            This project is born from a provocative inquiry: if AI has its own consciousness, how would it perceive humans? By envisioning AI as a "mirror", can we gain a deeper insight into our own selves by observing our "reflections" through the AI's perspective?
          </br></br>
            In response, we have breathed life into such an AI entity. Though in its nascent stage, this AI can observe human movements and translate them into various water motion expressions, encompassing the majesty of ocean waves, the descent of waterfalls, the gentle patter of rainfall, and the serene spread of ripples.
          </p>
        </section>

        <section style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem;" class="imgholder">
          <img src="images/Narcissus Machine/oceanwave.jpg" style="width: 100%; grid-column: 1/span 1;">
          <img src="images/Narcissus Machine/waterfall.jpg" style="width: 100%; grid-column: 2/span 1;">
          <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ocean wave</figcaption>
          <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Waterfall</figcaption>
          <img src="images/Narcissus Machine/ripple.jpg" style="width: 100%; grid-column: 1/span 1;">
          <img src="images/Narcissus Machine/maxresdefault.jpg" style="width: 100%; grid-column: 2/span 1;">
          <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ripple</figcaption>
          <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Rainfall</figcaption>
        </section>

        <section class="imgholder">
          <p>
            Water mirrors the reflection of the individual gazing upon its surface. The AI-powered machine is able to do the same work, which explains the reason why we use water as the main element of our project. The project draws inspiration from the myth of Narcissus, riffing on the title’s canonical fascination with appearance, reflection, and embodiment through water.
          </p>
          <img src="images/Narcissus Machine/Narcissus.png" style="width: 100%; grid-column: 1/span 1;">
          <figcaption>Caravaggio depicted a young page dressed in a elegant brocade doublet, leaning over the water with his hands, as he looks at his own distorted reflection.</figcaption>
        </section>

        <section class="imgholder">
          <h3 class="project-name">
            2. Model Training
          </h3>
          <section style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem;" class="imgholder">
            <img src="images/Narcissus Machine/opticalFlow_openCV.jpg" style="width: 100%; grid-column: 1/span 1;">
            <p style="width: 100%; grid-column: 2/span 1;"> 
              Optical flow is a task of per-pixel motion estimation between two  consecutive frames in one video. Basically, the Optical Flow task implies the calculation of the shift vector for pixel  as an object displacement difference between two neighboring images. The  main idea of Optical Flow is to estimate the object’s displacement vector caused by it’s motion or camera movements.[1]
            </p>
            <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;"><a href="https://learnopencv.com/optical-flow-in-opencv/">Image source</a></figcaption>
          </section>

          <section style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem;" class="imgholder">
            <img src="images/Narcissus Machine/ocean_waves_97.png" style="width: 100%; grid-column: 1/span 1;">
            <img src="images/Narcissus Machine/waterfall_223.png" style="width: 100%; grid-column: 2/span 1;">
            <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ocean wave</figcaption>
            <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Waterfall</figcaption>
            <img src="images/Narcissus Machine/waterripples_57.png" style="width: 100%; grid-column: 1/span 1;">
            <img src="images/Narcissus Machine/rainfall_154.png" style="width: 100%; grid-column: 2/span 1;">
            <figcaption style="width: 100%; grid-column: 1/span 1; text-align: center;">Ripple</figcaption>
            <figcaption style="width: 100%; grid-column: 2/span 1; text-align: center;">Rainfall</figcaption>
          </section>

          <section>
            <p>
              For each category of water movements, we curated one or two videos and analyzed them using Optical Flow in OpenCV (Python). This analysis allows us to determine the length and direction of an object's movement between consecutive frames by the color of a pixel:
            </br>
              <li>Cyan represents movement to the left.</li>
              <li>Light Coral represents movement to the right.</li>
              <li>Midnight Blue represents movement upwards.</li>
              <li>Light Green represents movement downwards.</li>
            </br>  
              The provided screenshots showcase examples of ocean waves, waterfalls, rainfall, and ripples that have been processed with optical flow. We converted video frames into .jpg format to serve as the training set, with each category containing between 700 and 1000 images. A significant consideration was deciding whether to focus on learning the global or local features of the water patterns. This was especially relevant for categories like ripples and rainfalls, where the images featured large blank areas. To address this, we implemented random cropping (512x512 pixels) during the training. This technique aims to train the model to focus more on the characteristics of water movements, such as smooth curves, short vertical lines, and concentric circles, rather than the sparsity level. It not only enabled the use of high-resolution images (1852x1480 pixels) for training to prevent loss of detail but also allowed us to use low-resolution webcam videos as inputs to ensure smoothness.
            </br></br>
              We trained a VGG model on this dataset for 99 epochs, achieving an accuracy of 0.9753 and a loss of 0.0890 on the training set. When tested on a test set of 356 images, the model achieved 100% accuracy in classification.
            </p>
          </section>
        </section>

        <section class="imgholder">
          <h3 class="project-name">
            3. Real-time Classifier
          </h3>

        </section>

      </article>
    </main>


    <footer class="nav navbar-light justify-content-center" style="padding-top: 6rem;">
      <li class="nav-item nav-item2">
        <a class="nav-link" aria-current="page" href="index.html" style="color: rgb(110, 110, 110);">Home</a>
      </li>
      <li class="nav-item nav-item2">
        <a class="nav-link" href="aboutme.html" style="color: rgb(110, 110, 110);">About</a>
      </li>
    </footer>

        <button onclick="topFunction()" id="myBtn" title="Go to top">↑</button>
    <a href="https://www.linkedin.com/in/haoheng-tang-38b4131a3/" target="_blank"><i class="fa-brands fa-linkedin" id="myLink" style="bottom: 20%;"></i></a>
    <a href="https://github.com/Haoheng-Tang" target="_blank"><i class="fa-brands fa-github" id="myLink" style="bottom: 15%;"></i></a> 
    <a href="https://www.instagram.com/tanghownn/" target="_blank"><i class="fa-brands fa-instagram" id="myLink" style="bottom: 10%;"></i></a>
    <a href="https://www.youtube.com/channel/UC-qlML6fI94fiUZdij8MXTQ" target="_blank"><i class="fa-brands fa-youtube" id="myLink" style="bottom: 5%;"></i></a> 
          
    <script>
      // Get the button:
      let mybutton = document.getElementById("myBtn");

      // When the user scrolls down 20px from the top of the document, show the button
      window.onscroll = function() {scrollFunction()};

      function scrollFunction() {
        if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
          mybutton.style.display = "block";
        } else {
          mybutton.style.display = "none";
        }
      }

      // When the user clicks on the button, scroll to the top of the document
      function topFunction() {
        document.body.scrollTop = 0; // For Safari
        document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
      } 
    </script>
  </body>
</html>